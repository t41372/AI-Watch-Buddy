"""
TTSé›†æˆæµ‹è¯•æ–‡ä»¶ - Base64ç‰ˆæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨TTSç”Ÿæˆå™¨å¤„ç†è§†é¢‘åˆ†æç»“æœ
æ”¯æŒç”¨æˆ·äº¤äº’å¼é€‰æ‹©è¯­éŸ³éŸ³è‰²ï¼Œè¾“å‡ºbase64éŸ³é¢‘æ•°æ®
"""

from tts_generator import TTSGenerator, quick_video_to_speech
import os
import json
import base64
from datetime import datetime
from pathlib import Path

from tts_generator import TTSGenerator, quick_video_to_speech
import os
import json
import base64
from datetime import datetime
from pathlib import Path


class TTSBase64Manager:
    """TTS Base64ç®¡ç†å™¨ï¼ŒåŸºäºMiniMax TTSå¼•æ“ï¼Œè¾“å‡ºbase64éŸ³é¢‘æ•°æ®"""

    def __init__(self):
        self.tts_generator = TTSGenerator()
        print("âœ… TTS Base64ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ (MiniMax)")

    def generate_speech_base64(self, text: str, voice_id: str = None) -> dict:
        """
        ç”Ÿæˆè¯­éŸ³çš„base64æ•°æ®

        Args:
            text: è¦è½¬æ¢çš„æ–‡æœ¬
            voice_id: è¯­éŸ³ID

        Returns:
            dict: åŒ…å«ç»“æœä¿¡æ¯çš„å­—å…¸
        """
        try:
            print(f"ğŸ”„ ç”Ÿæˆè¯­éŸ³: {text[:30]}... (ä½¿ç”¨MiniMax TTS)")

            # ä½¿ç”¨ç°æœ‰çš„generate_single_audioæ–¹æ³•ï¼Œä½†ä¸ä¿å­˜æ–‡ä»¶
            audio_bytes = self.tts_generator.generate_single_audio(
                text=text,
                voice_id=voice_id,
                output_path=None,  # ä¸ä¿å­˜æ–‡ä»¶
            )

            if audio_bytes:
                base64_audio = base64.b64encode(audio_bytes).decode("utf-8")
                return {
                    "success": True,
                    "text": text,
                    "voice_id": voice_id or self.tts_generator.default_voice_id,
                    "base64_audio": base64_audio,
                    "audio_length": len(base64_audio),
                    "audio_size_bytes": len(audio_bytes),
                    "timestamp": datetime.now().isoformat(),
                }
            else:
                return {
                    "success": False,
                    "text": text,
                    "voice_id": voice_id,
                    "error": "è¯­éŸ³ç”Ÿæˆå¤±è´¥",
                    "timestamp": datetime.now().isoformat(),
                }

        except Exception as e:
            print(f"âŒ è¯­éŸ³ç”Ÿæˆå¼‚å¸¸: {e}")
            return {
                "success": False,
                "text": text,
                "voice_id": voice_id,
                "error": str(e),
                "timestamp": datetime.now().isoformat(),
            }

    def process_text_batch(self, texts: list, voice_id: str = None) -> dict:
        """
        æ‰¹é‡å¤„ç†æ–‡æœ¬ç”Ÿæˆè¯­éŸ³base64æ•°æ®

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            voice_id: è¯­éŸ³ID

        Returns:
            dict: æ‰¹é‡å¤„ç†ç»“æœ
        """
        results = []
        successful_count = 0

        print(f"\nğŸµ å¼€å§‹æ‰¹é‡ç”Ÿæˆè¯­éŸ³ (å…± {len(texts)} æ¡) - MiniMax TTS")
        print("=" * 60)

        for i, text in enumerate(texts, 1):
            print(f"ğŸ”„ å¤„ç† {i}/{len(texts)}: {text[:40]}...")

            result = self.generate_speech_base64(text, voice_id)
            results.append(result)

            if result["success"]:
                successful_count += 1
                print(
                    f"âœ… æˆåŠŸ - éŸ³é¢‘é•¿åº¦: {result['audio_length']} å­—ç¬¦ ({result['audio_size_bytes']} bytes)"
                )
            else:
                print(f"âŒ å¤±è´¥ - {result['error']}")

        return {
            "success": True,
            "total_texts": len(texts),
            "successful_generations": successful_count,
            "results": results,
            "voice_id": voice_id or self.tts_generator.default_voice_id,
            "timestamp": datetime.now().isoformat(),
        }


def get_user_voice_choice():
    """
    äº¤äº’å¼è·å–ç”¨æˆ·é€‰æ‹©çš„è¯­éŸ³
    è¿”å›é€‰æ‹©çš„è¯­éŸ³IDå’Œåç§°
    """
    print("\nğŸ¤ é€‰æ‹©è¯­éŸ³éŸ³è‰²")
    print("=" * 40)

    # MiniMaxæ¨èéŸ³è‰²é€‰é¡¹
    voice_options = [
        {"id": "female-zh", "name": "å¥³å£°1 - å®˜æ–¹ä¸­æ–‡å¥³å£°", "desc": "ä¸­æ–‡, å¥³å£°"},
        {"id": "male-zh", "name": "ç”·å£°1 - å®˜æ–¹ä¸­æ–‡ç”·å£°", "desc": "ä¸­æ–‡, ç”·å£°"},
        {"id": "female-en", "name": "å¥³å£°2 - è‹±æ–‡å¥³å£°", "desc": "è‹±æ–‡, å¥³å£°"},
        {"id": "male-en", "name": "ç”·å£°2 - è‹±æ–‡ç”·å£°", "desc": "è‹±æ–‡, ç”·å£°"},
    ]

    print("ğŸ“‹ æ¨èéŸ³è‰²é€‰é¡¹:")
    for i, voice in enumerate(voice_options, 1):
        print(f"{i}. {voice['name']} - {voice['desc']}")
        print("-" * 30)
    print(f"{len(voice_options) + 1}. æŸ¥çœ‹æ‰€æœ‰å¯ç”¨éŸ³è‰²")
    print(f"{len(voice_options) + 2}. ä½¿ç”¨é»˜è®¤éŸ³è‰² (å¥³å£°1)")

    while True:
        try:
            choice = input(f"\nè¯·é€‰æ‹©éŸ³è‰² (1-{len(voice_options) + 2}): ").strip()
            if not choice:
                print("âš ï¸  è¯·è¾“å…¥é€‰æ‹©")
                continue
            choice_num = int(choice)
            if 1 <= choice_num <= len(voice_options):
                selected_voice = voice_options[choice_num - 1]
                print(
                    f"\nâœ… æ‚¨é€‰æ‹©äº†: {selected_voice['name']} - {selected_voice['desc']}"
                )
                return selected_voice["id"], selected_voice["name"]
            elif choice_num == len(voice_options) + 1:
                # æŸ¥çœ‹æ‰€æœ‰å¯ç”¨éŸ³è‰²
                return get_all_voices_choice()
            elif choice_num == len(voice_options) + 2:
                # ä½¿ç”¨é»˜è®¤éŸ³è‰²
                print(f"\nâœ… ä½¿ç”¨é»˜è®¤éŸ³è‰²: å¥³å£°1")
                return None, "å¥³å£°1 (é»˜è®¤)"
            else:
                print(f"âš ï¸  è¯·è¾“å…¥ 1 åˆ° {len(voice_options) + 2} ä¹‹é—´çš„æ•°å­—")
        except ValueError:
            print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\n\nâš ï¸  ç”¨æˆ·å–æ¶ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤éŸ³è‰²")
            return None, "å¥³å£°1 (é»˜è®¤)"


def get_all_voices_choice():
    """
    æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨è¯­éŸ³ä¾›ç”¨æˆ·é€‰æ‹©
    """
    try:
        print("\nğŸ”„ è·å–æ‰€æœ‰å¯ç”¨è¯­éŸ³...")
        tts_gen = TTSGenerator()
        voices = tts_gen.get_available_voices()
        if not voices:
            print("âŒ æ— æ³•è·å–è¯­éŸ³åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤è¯­éŸ³")
            return None, "George (é»˜è®¤)"
        print(f"\nğŸ¤ æ‰€æœ‰å¯ç”¨è¯­éŸ³ (å…± {len(voices)} ä¸ª):")
        print("=" * 60)
        for i, voice in enumerate(voices, 1):
            print(f"{i:2d}. {voice['name']} ({voice['voice_id']})")
            if voice["description"]:
                print(f"     æè¿°: {voice['description']}")
            print("-" * 40)
        print(f"{len(voices) + 1}. è¿”å›æ¨èåˆ—è¡¨")
        print(f"{len(voices) + 2}. ä½¿ç”¨é»˜è®¤è¯­éŸ³")
        while True:
            try:
                choice = input(f"\nè¯·é€‰æ‹©è¯­éŸ³ (1-{len(voices) + 2}): ").strip()
                if not choice:
                    continue
                choice_num = int(choice)
                if 1 <= choice_num <= len(voices):
                    selected_voice = voices[choice_num - 1]
                    print(f"\nâœ… æ‚¨é€‰æ‹©äº†: {selected_voice['name']}")
                    return selected_voice["voice_id"], selected_voice["name"]
                elif choice_num == len(voices) + 1:
                    return get_user_voice_choice()  # è¿”å›æ¨èåˆ—è¡¨
                elif choice_num == len(voices) + 2:
                    print(f"\nâœ… ä½¿ç”¨é»˜è®¤è¯­éŸ³: George")
                    return None, "George (é»˜è®¤)"
                else:
                    print(f"âš ï¸  è¯·è¾“å…¥ 1 åˆ° {len(voices) + 2} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
            except KeyboardInterrupt:
                print("\n\nâš ï¸  ç”¨æˆ·å–æ¶ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤è¯­éŸ³")
                return None, "George (é»˜è®¤)"
    except Exception as e:
        print(f"âŒ è·å–è¯­éŸ³åˆ—è¡¨å¤±è´¥: {e}")
        print("ä½¿ç”¨é»˜è®¤è¯­éŸ³")
        return None, "George (é»˜è®¤)"


def preview_voice_sample(voice_id, voice_name):
    """
    é¢„è§ˆè¯­éŸ³æ ·æœ¬ - ç”Ÿæˆbase64æ•°æ®ç‰ˆæœ¬
    """
    try:
        print(f"\nğŸ”Š æ­£åœ¨ç”Ÿæˆ {voice_name} çš„è¯­éŸ³é¢„è§ˆ...")

        sample_texts = [
            "ä½ å¥½ï¼Œæ¬¢è¿è§‚çœ‹ä»Šå¤©çš„è§†é¢‘å†…å®¹ï¼",
            "å“ˆå“ˆå“ˆè¿™ä¹Ÿå¤ªæç¬‘äº†å§ï¼",
            "å‘œå‘œå‘œå¥½æ„ŸåŠ¨å•Šï¼",
        ]

        tts_manager = TTSBase64Manager()
        preview_results = []

        for i, text in enumerate(sample_texts, 1):
            print(f"  ç”Ÿæˆæ ·æœ¬ {i}/3: {text}")

            import asyncio

            result = tts_manager.generate_speech_base64(text, voice_id)

            if result["success"]:
                preview_results.append(result)
                print(f"    âœ… ç”ŸæˆæˆåŠŸ - éŸ³é¢‘é•¿åº¦: {result['audio_length']} å­—ç¬¦")

                # ä¿å­˜é¢„è§ˆæ•°æ®åˆ°JSONæ–‡ä»¶
                output_file = f"./test_output/voice_preview_{voice_name.replace(' ', '_')}_{i}.json"
                os.makedirs("./test_output", exist_ok=True)
                with open(output_file, "w", encoding="utf-8") as f:
                    json.dump(result, f, ensure_ascii=False, indent=2)
                print(f"    ğŸ’¾ é¢„è§ˆæ•°æ®å·²ä¿å­˜: {output_file}")
            else:
                print(f"    âŒ ç”Ÿæˆå¤±è´¥: {result['error']}")

        print(f"\nğŸ’¡ è¯­éŸ³é¢„è§ˆå®Œæˆï¼Œç”Ÿæˆäº† {len(preview_results)} ä¸ªæ ·æœ¬")
        print("ğŸ’¡ æ‰€æœ‰éŸ³é¢‘æ•°æ®éƒ½ä»¥base64æ ¼å¼ä¿å­˜ï¼Œå¯ç›´æ¥ç”¨äºWebSocketä¼ è¾“")

        # è¯¢é—®æ˜¯å¦ç¡®è®¤ä½¿ç”¨æ­¤è¯­éŸ³
        while True:
            confirm = input(f"\nç¡®è®¤ä½¿ç”¨ {voice_name} è¯­éŸ³å—ï¼Ÿ(y/n): ").strip().lower()
            if confirm in ["y", "yes", "æ˜¯", "ç¡®è®¤"]:
                return True
            elif confirm in ["n", "no", "å¦", "å–æ¶ˆ"]:
                return False
            else:
                print("è¯·è¾“å…¥ y/n")

    except Exception as e:
        print(f"âŒ è¯­éŸ³é¢„è§ˆå¤±è´¥: {e}")
        return True  # é¢„è§ˆå¤±è´¥æ—¶é»˜è®¤ç¡®è®¤ä½¿ç”¨


def test_simple_base64_tts():
    """æµ‹è¯•ç®€å•çš„Base64 TTSåŠŸèƒ½"""
    print("\nğŸ“ æµ‹è¯•1: ç®€å•Base64 TTSåŠŸèƒ½")
    print("=" * 50)

    tts_manager = TTSBase64Manager()

    # é€‰æ‹©è¯­éŸ³
    voice_id, voice_name = get_user_voice_choice()

    # æµ‹è¯•æ–‡æœ¬
    test_texts = [
        "ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„AIè¯­éŸ³é™ªä¼´ï¼",
        "å“ˆå“ˆå“ˆè¿™ä¸ªè§†é¢‘å¤ªæç¬‘äº†ï¼",
        "å‘œå‘œå‘œå¥½æ„ŸåŠ¨ï¼Œæˆ‘éƒ½è¦å“­äº†ï¼",
        "è¯¶ï¼Ÿè¿™æ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿæˆ‘æœ‰ç‚¹æ‡µï¼",
    ]

    print(f"\nğŸ§ª ä½¿ç”¨ {voice_name} æµ‹è¯• {len(test_texts)} æ¡æ–‡æœ¬...")

    # æ‰¹é‡å¤„ç†
    result = tts_manager.process_text_batch(test_texts, voice_id)

    if result["success"]:
        print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼")
        print(
            f"ğŸ“Š æˆåŠŸç”Ÿæˆ: {result['successful_generations']}/{result['total_texts']}"
        )

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        output_file = f"./test_output/tts_base64_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs("./test_output", exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print(f"ğŸ’¾ Base64ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        # æ˜¾ç¤ºéƒ¨åˆ†ç»“æœä¿¡æ¯
        print(f"\nğŸ“‹ ç»“æœé¢„è§ˆ:")
        for i, res in enumerate(result["results"][:2], 1):
            if res["success"]:
                print(f"  {i}. æ–‡æœ¬: {res['text'][:30]}...")
                print(f"     éŸ³é¢‘é•¿åº¦: {res['audio_length']} å­—ç¬¦")
                print(f"     éŸ³é¢‘å¤§å°: {res['audio_size_bytes']} bytes")
                print(f"     base64å‰ç¼€: {res['base64_audio'][:50]}...")
            else:
                print(f"  {i}. å¤±è´¥: {res['error']}")

        print(f"\nğŸ’¡ æ‰€æœ‰éŸ³é¢‘æ•°æ®éƒ½ä»¥base64æ ¼å¼å­˜å‚¨ï¼Œå¯ç›´æ¥ç”¨äºWebSocketä¼ è¾“")
    else:
        print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥")


def test_video_reaction_base64():
    """æ¨¡æ‹Ÿè§†é¢‘ååº”çš„Base64 TTSå¤„ç†"""
    print("\nğŸ“ æµ‹è¯•2: æ¨¡æ‹Ÿè§†é¢‘ååº”Base64 TTS")
    print("=" * 50)

    tts_manager = TTSBase64Manager()

    # é€‰æ‹©è¯­éŸ³
    voice_id, voice_name = get_user_voice_choice()

    # æ¨¡æ‹Ÿè§†é¢‘åˆ†æç»“æœ
    mock_video_reactions = [
        {"timestamp": 0.0, "text": "å“‡ï¼è¿™ä¸ªè§†é¢‘å¼€å§‹äº†ï¼æˆ‘å¥½æœŸå¾…å•Šï¼"},
        {"timestamp": 15.2, "text": "å“ˆå“ˆå“ˆå“ˆï¼è¿™ä¹Ÿå¤ªæç¬‘äº†å§ï¼"},
        {"timestamp": 32.5, "text": "è¯¶ï¼Ÿè¿™ä¸ªè½¬æŠ˜æˆ‘æ²¡æƒ³åˆ°ï¼"},
        {"timestamp": 48.7, "text": "å‘œå‘œå‘œï¼Œå¥½æ„ŸåŠ¨å•Šï¼Œæˆ‘éƒ½è¦å“­äº†ï¼"},
        {"timestamp": 65.1, "text": "ç­‰ç­‰ç­‰ç­‰ï¼Œè¿™æ˜¯ä»€ä¹ˆç¥æ“ä½œï¼Ÿ"},
        {"timestamp": 80.3, "text": "å¤ªå‰å®³äº†ï¼æˆ‘å­¦åˆ°äº†æ–°ä¸œè¥¿ï¼"},
        {"timestamp": 95.8, "text": "è¿™ä¸ªè§†é¢‘çœŸçš„å¾ˆæ£’ï¼Œè°¢è°¢åˆ†äº«ï¼"},
    ]

    print(f"\nğŸ¬ æ¨¡æ‹Ÿå¤„ç† {len(mock_video_reactions)} ä¸ªè§†é¢‘ååº”...")
    print(f"ğŸµ ä½¿ç”¨è¯­éŸ³: {voice_name}")

    # æå–æ–‡æœ¬
    texts = [reaction["text"] for reaction in mock_video_reactions]

    # æ‰¹é‡ç”Ÿæˆ
    result = tts_manager.process_text_batch(texts, voice_id)

    if result["success"]:
        # åˆå¹¶æ—¶é—´æˆ³ä¿¡æ¯
        enhanced_results = []
        for i, (reaction, tts_result) in enumerate(
            zip(mock_video_reactions, result["results"])
        ):
            enhanced_result = {
                **tts_result,
                "timestamp": reaction["timestamp"],
                "reaction_index": i,
            }
            enhanced_results.append(enhanced_result)

        # ä¿å­˜å®Œæ•´ç»“æœ
        output_data = {
            "video_info": {
                "total_reactions": len(mock_video_reactions),
                "voice_used": voice_name,
                "voice_id": voice_id or tts_manager.tts_generator.default_voice_id,
                "processing_time": datetime.now().isoformat(),
            },
            "tts_summary": {
                "total_texts": result["total_texts"],
                "successful_generations": result["successful_generations"],
                "success_rate": f"{(result['successful_generations'] / result['total_texts'] * 100):.1f}%",
            },
            "reactions": enhanced_results,
        }

        output_file = f"./test_output/video_reaction_base64_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        os.makedirs("./test_output", exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ‰ è§†é¢‘ååº”Base64 TTSå¤„ç†å®Œæˆï¼")
        print(f"ğŸ“Š æˆåŠŸç‡: {output_data['tts_summary']['success_rate']}")
        print(f"ğŸ’¾ å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

        # æ˜¾ç¤ºæ—¶é—´è½´é¢„è§ˆ
        print(f"\nâ° ååº”æ—¶é—´è½´é¢„è§ˆ:")
        for reaction in enhanced_results[:3]:
            if reaction["success"]:
                print(f"  {reaction['timestamp']:>6.1f}s: {reaction['text'][:40]}...")
                print(
                    f"           éŸ³é¢‘: {reaction['audio_size_bytes']} bytes -> {reaction['audio_length']} chars (base64)"
                )
            else:
                print(f"  {reaction['timestamp']:>6.1f}s: âŒ {reaction['error']}")

        print(f"\nğŸ’¡ æ‰€æœ‰éŸ³é¢‘æ•°æ®éƒ½ä»¥base64æ ¼å¼å­˜å‚¨ï¼Œé€‚åˆWebSocketå®æ—¶ä¼ è¾“")
    else:
        print(f"âŒ è§†é¢‘ååº”Base64 TTSå¤„ç†å¤±è´¥")


def test_video_to_speech_base64():
    """æµ‹è¯•è§†é¢‘åˆ†æ + Base64 TTSè¯­éŸ³ç”Ÿæˆå®Œæ•´æµç¨‹"""

    # é…ç½®å‚æ•°
    video_path = r"C:\Users\86182\Desktop\31182686022-1-192.mp4"  # ä½ çš„è§†é¢‘è·¯å¾„
    output_dir = "./batch_test_output_base64"  # è¾“å‡ºç›®å½•

    print("ğŸ¬ğŸµ å¼€å§‹è§†é¢‘åˆ†æ + Base64 TTSè¯­éŸ³ç”Ÿæˆæµ‹è¯•")
    print("=" * 60)

    # ç”¨æˆ·é€‰æ‹©è¯­éŸ³
    print("\nğŸ¤ é¦–å…ˆé€‰æ‹©æ‚¨å–œæ¬¢çš„è¯­éŸ³éŸ³è‰²...")
    voice_id, voice_name = get_user_voice_choice()

    # æ˜¯å¦è¦é¢„è§ˆè¯­éŸ³æ ·æœ¬
    if voice_id:  # å¦‚æœé€‰æ‹©äº†éé»˜è®¤è¯­éŸ³
        preview_choice = (
            input(f"\næ˜¯å¦è¦é¢„è§ˆ {voice_name} çš„è¯­éŸ³æ ·æœ¬ï¼Ÿ(y/n): ").strip().lower()
        )
        if preview_choice in ["y", "yes", "æ˜¯"]:
            if not preview_voice_sample(voice_id, voice_name):
                print("é‡æ–°é€‰æ‹©è¯­éŸ³...")
                voice_id, voice_name = get_user_voice_choice()

    print(f"\nğŸµ å°†ä½¿ç”¨è¯­éŸ³: {voice_name}")
    if voice_id:
        print(f"ğŸ†” è¯­éŸ³ID: {voice_id}")

    # ç³»ç»Ÿæç¤ºè¯ï¼ˆä½¿ç”¨ä½ ä¹‹å‰ä¼˜åŒ–è¿‡çš„ï¼‰
    system_prompt = """# SYSTEM PROMPT

You are reacting to a video with your human friend (the user). Your task is to generate a "Reaction Script" in JSON format that details the sequence of actions you will take while watching a video. Your reaction should be natural, engaging, and feel like a real person watching and commenting.

## è§’è‰²è®¾å®š
ä¸‹é¢ä½ å°†æ‰®æ¼”çš„è§’è‰²å…·æœ‰ä»¥ä¸‹ç‰¹å¾ï¼š

**æ ¸å¿ƒäººè®¾ï¼š**

**è¯­è¨€é£æ ¼ï¼š**

**ååº”ç‰¹ç‚¹ï¼š**

## è¾“å‡ºè§„åˆ™
**RULES:**
1. You MUST output a valid JSON object that strictly adheres to the provided JSON Schema.
2. Your output MUST be a single JSON object, starting with { and ending with }.
3. Use the comment field in each action object to explain your thought process.
4. Make your speech (text in SPEAK actions) lively and in character as defined.
5. The final action MUST be "END_REACTION" or "ASK_USER".

**JSON SCHEMA:** [çœç•¥å…·ä½“schemaä»¥èŠ‚çœç©ºé—´]
"""

    user_prompt = "è¯·åˆ†æè¿™ä¸ªè§†é¢‘ä¸­çš„ä¸»è¦åŠ¨ä½œå’Œæƒ…æ„Ÿå˜åŒ–ï¼Œä¸ºæ¡Œå® ç”Ÿæˆç›¸åº”çš„ååº”åŠ¨ä½œã€‚"

    try:
        print(f"\nğŸ“ å¼€å§‹å¤„ç†è§†é¢‘ï¼Œä½¿ç”¨è¯­éŸ³: {voice_name}")

        # 1. åˆ›å»ºTTSç®¡ç†å™¨
        tts_manager = TTSBase64Manager()

        # 2. ä½¿ç”¨ç°æœ‰çš„è§†é¢‘åˆ†æåŠŸèƒ½
        from ai_watch_buddy.prompts.video_analyzer import invoke_gemini_vids

        print("ğŸ¬ å¼€å§‹è§†é¢‘åˆ†æ...")
        analysis_result = invoke_gemini_vids(
            video_path=video_path, system_prompt=system_prompt, user_prompt=user_prompt
        )

        if not analysis_result.get("success"):
            print(f"âŒ è§†é¢‘åˆ†æå¤±è´¥: {analysis_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return

        # 3. æå–æ‰€æœ‰SPEAKåŠ¨ä½œçš„æ–‡æœ¬
        action_list = analysis_result["action_list"]
        speak_actions = [
            action for action in action_list if action.get("action_type") == "SPEAK"
        ]

        if not speak_actions:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•SPEAKåŠ¨ä½œ")
            return

        print(f"ğŸ—£ï¸  æ‰¾åˆ° {len(speak_actions)} æ¡è¯­éŸ³åŠ¨ä½œ")

        # 4. æå–æ–‡æœ¬å¹¶æ‰¹é‡ç”Ÿæˆbase64éŸ³é¢‘
        texts = [
            action.get("text", "").strip()
            for action in speak_actions
            if action.get("text", "").strip()
        ]

        import asyncio

        batch_result = tts_manager.process_text_batch(texts, voice_id)

        if batch_result["success"]:
            # 5. åˆå¹¶æ—¶é—´æˆ³å’Œå…¶ä»–ä¿¡æ¯
            enhanced_results = []
            for i, (action, tts_result) in enumerate(
                zip(speak_actions, batch_result["results"])
            ):
                enhanced_result = {
                    **tts_result,
                    "action_id": action.get("id"),
                    "timestamp": action.get("trigger_timestamp", 0),
                    "action_index": i,
                    "comment": action.get("comment", ""),
                }
                enhanced_results.append(enhanced_result)

            # 6. åˆ›å»ºå®Œæ•´çš„è¾“å‡ºæ•°æ®
            complete_result = {
                "video_info": {
                    "video_path": video_path,
                    "total_actions": len(action_list),
                    "speak_actions": len(speak_actions),
                    "voice_used": voice_name,
                    "voice_id": voice_id or tts_manager.tts_generator.default_voice_id,
                    "processing_time": datetime.now().isoformat(),
                },
                "tts_summary": {
                    "total_texts": batch_result["total_texts"],
                    "successful_generations": batch_result["successful_generations"],
                    "success_rate": f"{(batch_result['successful_generations'] / batch_result['total_texts'] * 100):.1f}%",
                },
                "audio_data": enhanced_results,
                "original_actions": action_list,  # ä¿ç•™åŸå§‹åŠ¨ä½œåˆ—è¡¨
            }

            # 7. ä¿å­˜ç»“æœ
            os.makedirs(output_dir, exist_ok=True)
            output_file = f"{output_dir}/video_tts_base64_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(complete_result, f, ensure_ascii=False, indent=2)

            print(f"\nâœ… è§†é¢‘åˆ†æ + Base64 TTSå¤„ç†æˆåŠŸï¼")
            print(f"ğŸµ ä½¿ç”¨è¯­éŸ³: {voice_name}")
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
            print(
                f"ğŸµ æˆåŠŸç”Ÿæˆ: {batch_result['successful_generations']}/{batch_result['total_texts']} ä¸ªbase64éŸ³é¢‘"
            )
            print(f"ï¿½ æˆåŠŸç‡: {complete_result['tts_summary']['success_rate']}")

            # æ˜¾ç¤ºéƒ¨åˆ†ç”Ÿæˆçš„ç»“æœ
            print(f"\nğŸ“„ ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®ç¤ºä¾‹:")
            for i, audio_data in enumerate(enhanced_results[:3]):
                if audio_data["success"]:
                    print(f"  {i + 1}. æ—¶é—´: {audio_data['timestamp']}s")
                    print(f"     æ–‡æœ¬: {audio_data['text'][:40]}...")
                    print(
                        f"     éŸ³é¢‘: {audio_data['audio_size_bytes']} bytes -> {audio_data['audio_length']} chars (base64)"
                    )
                else:
                    print(f"  {i + 1}. âŒ å¤±è´¥: {audio_data['error']}")

            if len(enhanced_results) > 3:
                print(f"     ... è¿˜æœ‰ {len(enhanced_results) - 3} ä¸ªéŸ³é¢‘æ•°æ®")

            print(f"\nğŸ’¡ æ‰€æœ‰éŸ³é¢‘æ•°æ®éƒ½ä»¥base64æ ¼å¼å­˜å‚¨ï¼Œå¯ç›´æ¥ç”¨äºWebSocketä¼ è¾“")

        else:
            print(f"âŒ æ‰¹é‡TTSå¤„ç†å¤±è´¥")

    except Exception as e:
        print(f"âŒ å¤„ç†å¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()


def test_custom_voice_comparison():
    """æµ‹è¯•å¤šç§è¯­éŸ³å¯¹æ¯”"""

    print("\nğŸ“ è¯­éŸ³å¯¹æ¯”æµ‹è¯•")
    print("=" * 40)

    # æµ‹è¯•æ–‡æœ¬
    test_text = "å“ˆå“ˆå“ˆè¿™ä¹Ÿå¤ªæç¬‘äº†å§ï¼æˆ‘ç¬‘æ­»äº†ï¼"

    # å¤šä¸ªè¯­éŸ³è¿›è¡Œå¯¹æ¯”
    voice_options = [
        ("JBFqnCBsd6RMkjVDRZzb", "George"),
        ("EXAVITQu4vr4xnSDxMaL", "Sarah"),
        ("cgSgspJ2msm6clMCkdW9", "Jessica"),
        ("TX3LPaxmHKxFdv7VOQHJ", "Liam"),
    ]

    try:
        tts_gen = TTSGenerator()

        print(f"ğŸ§ª ç”¨æ–‡æœ¬ '{test_text}' æµ‹è¯•ä¸åŒè¯­éŸ³:")
        print("-" * 50)

        for voice_id, voice_name in voice_options:
            print(f"\nğŸ¤ æµ‹è¯•è¯­éŸ³: {voice_name}")

            output_path = f"./test_output/comparison_{voice_name.lower()}.mp3"
            audio = tts_gen.generate_single_audio(
                text=test_text,
                voice_id=voice_id,
                output_path=output_path,
                play_audio=False,
            )

            if audio:
                print(f"âœ… ç”ŸæˆæˆåŠŸ: {output_path}")
            else:
                print(f"âŒ ç”Ÿæˆå¤±è´¥")

        print(f"\nğŸ’¡ å¯¹æ¯”æ–‡ä»¶å·²ä¿å­˜åˆ° ./test_output/ ç›®å½•")
        print("å¯ä»¥æ’­æ”¾è¿™äº›æ–‡ä»¶æ¥å¯¹æ¯”ä¸åŒè¯­éŸ³çš„æ•ˆæœ")

    except Exception as e:
        print(f"âŒ è¯­éŸ³å¯¹æ¯”æµ‹è¯•å¤±è´¥: {e}")
    """æµ‹è¯•è‡ªå®šä¹‰è¯­éŸ³"""

    print("\nğŸ“ æ–¹æ³•2: ä½¿ç”¨è‡ªå®šä¹‰è¯­éŸ³è®¾ç½®")

    try:
        # åˆ›å»ºTTSç”Ÿæˆå™¨
        tts_gen = TTSGenerator()

        # æ˜¾ç¤ºå¯ç”¨è¯­éŸ³ï¼ˆå¯é€‰ï¼‰
        print("\nğŸ¤ è·å–å¯ç”¨è¯­éŸ³åˆ—è¡¨...")
        voices = tts_gen.get_available_voices()
        if voices:
            print(f"æ‰¾åˆ° {len(voices)} ä¸ªå¯ç”¨è¯­éŸ³")
            # æ˜¾ç¤ºå‰5ä¸ªè¯­éŸ³
            for i, voice in enumerate(voices[:5]):
                print(
                    f"{i + 1}. {voice['name']} ({voice['voice_id']}) - {voice['category']}"
                )

        # æµ‹è¯•å•æ¡è¯­éŸ³ç”Ÿæˆ
        test_texts = [
            "å“ˆå“ˆå“ˆå“ˆè¿™ä¹Ÿå¤ªæç¬‘äº†å§ï¼",
            "å‘œå‘œå‘œæˆ‘å“­æ­»äº†å¥½æ„ŸåŠ¨å•Šï¼",
            "è¯¶ï¼Ÿè¿™æ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿ",
        ]

        print(f"\nğŸ§ª æµ‹è¯•è‡ªå®šä¹‰è¯­éŸ³ç”Ÿæˆ...")
        for i, text in enumerate(test_texts, 1):
            audio = tts_gen.generate_single_audio(
                text=text,
                output_path=f"./test_output/test_{i}_{text}.mp3",
                play_audio=False,
            )

            if audio:
                print(f"âœ… æµ‹è¯• {i}/3 æˆåŠŸ")
            else:
                print(f"âŒ æµ‹è¯• {i}/3 å¤±è´¥")

    except Exception as e:
        print(f"âŒ è‡ªå®šä¹‰è¯­éŸ³æµ‹è¯•å¤±è´¥: {e}")


def test_batch_processing():
    """æµ‹è¯•æ‰¹é‡å¤„ç†"""

    print("\nğŸ“ æ–¹æ³•3: ä½¿ç”¨å®Œæ•´çš„æ‰¹é‡å¤„ç†")

    video_path = r"C:\Users\86182\Desktop\31182686022-1-192.mp4"

    # ç®€åŒ–çš„ç³»ç»Ÿæç¤ºè¯
    simple_system_prompt = """
You are a cute AI character reacting to videos. Generate a JSON array of reactions.
Each reaction should have: action_type, trigger_timestamp, text (for SPEAK actions), comment.
Make your speech natural and engaging. Use SPEAK actions to comment on the video.
End with END_REACTION action.
"""

    user_prompt = "React to this video with enthusiasm and natural comments."

    try:
        tts_gen = TTSGenerator()

        result = tts_gen.process_video_analysis_to_speech(
            video_path=video_path,
            system_prompt=simple_system_prompt,
            user_prompt=user_prompt,
            output_dir="./batch_test_output",
            play_audio=False,  # è®¾ä¸ºTrueå¯ä»¥æ’­æ”¾éŸ³é¢‘
        )

        if result["success"]:
            print(f"ğŸ‰ æ‰¹é‡å¤„ç†æˆåŠŸï¼")
            print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            print(f"  - æ€»åŠ¨ä½œæ•°: {result['total_actions']}")
            print(f"  - æˆåŠŸç”Ÿæˆ: {result['successful_generations']}")
            print(f"  - è¾“å‡ºç›®å½•: {result['output_dir']}")
            print(f"  - å…ƒæ•°æ®: {result['metadata_path']}")

            # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
            if result["generated_files"]:
                print(f"\nğŸ“„ ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶:")
                for file_info in result["generated_files"][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"  - {file_info['file_path']}")
                    print(f"    æ–‡æœ¬: {file_info['text'][:50]}...")
                    print(f"    æ—¶é—´: {file_info['timestamp']}s")

                if len(result["generated_files"]) > 5:
                    print(f"  ... è¿˜æœ‰ {len(result['generated_files']) - 5} ä¸ªæ–‡ä»¶")
        else:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {result['error']}")

    except Exception as e:
        print(f"âŒ æ‰¹é‡å¤„ç†å¼‚å¸¸: {e}")


if __name__ == "__main__":
    print("ğŸµ TTSé›†æˆæµ‹è¯•å¼€å§‹ - Base64ç‰ˆæœ¬")
    print("=" * 60)

    # æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
    required_keys = ["MINIMAX_API_KEY", "GEMINI_API_KEY"]
    missing_keys = [key for key in required_keys if not os.getenv(key)]

    if missing_keys:
        print(f"âŒ ç¼ºå°‘å¿…è¦çš„ç¯å¢ƒå˜é‡: {', '.join(missing_keys)}")
        print("è¯·ç¡®ä¿ .env æ–‡ä»¶åŒ…å«æ‰€æœ‰å¿…è¦çš„APIå¯†é’¥")
        exit(1)

    try:
        # è¿è¡Œæµ‹è¯•
        test_simple_base64_tts()  # ç®€å•Base64 TTSæµ‹è¯•
        test_video_reaction_base64()  # è§†é¢‘ååº”Base64æµ‹è¯•
        test_video_to_speech_base64()  # å®Œæ•´æµç¨‹Base64æµ‹è¯•

        print("\nğŸ‰ TTSé›†æˆæµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ æ‰€æœ‰éŸ³é¢‘æ•°æ®éƒ½ä»¥base64æ ¼å¼å­˜å‚¨ï¼Œå¯ç›´æ¥ç”¨äºWebSocketä¼ è¾“")

    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback

        traceback.print_exc()
